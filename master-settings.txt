root@k001:~# kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=1.9.3


root@k001:~# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: ens33: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 00:0c:29:ce:ff:b9 brd ff:ff:ff:ff:ff:ff
    inet 10.1.0.204/24 brd 10.1.0.255 scope global ens33
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:fece:ffb9/64 scope link
       valid_lft forever preferred_lft forever
3: ens34: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 00:0c:29:ce:ff:c3 brd ff:ff:ff:ff:ff:ff
    inet 20.1.0.158/24 brd 20.1.0.255 scope global ens34
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:fece:ffc3/64 scope link
       valid_lft forever preferred_lft forever
4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default
    link/ether 02:42:6b:08:15:a5 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 scope global docker0
       valid_lft forever preferred_lft forever
5: datapath: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue state UNKNOWN group default qlen 1
    link/ether 96:76:40:80:10:61 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::9476:40ff:fe80:1061/64 scope link
       valid_lft forever preferred_lft forever
7: weave: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue state UP group default qlen 1000
    link/ether a6:71:1b:65:6b:81 brd ff:ff:ff:ff:ff:ff
    inet 10.32.0.1/12 brd 10.47.255.255 scope global weave
       valid_lft forever preferred_lft forever
    inet6 fe80::a471:1bff:fe65:6b81/64 scope link
       valid_lft forever preferred_lft forever
8: dummy0: <BROADCAST,NOARP> mtu 1500 qdisc noop state DOWN group default qlen 1000
    link/ether 8e:56:74:57:ea:da brd ff:ff:ff:ff:ff:ff
10: vethwe-datapath@vethwe-bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master datapath state UP group default
    link/ether de:1d:c5:74:24:77 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::dc1d:c5ff:fe74:2477/64 scope link
       valid_lft forever preferred_lft forever
11: vethwe-bridge@vethwe-datapath: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master weave state UP group default
    link/ether 3a:3c:1f:91:0f:86 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::383c:1fff:fe91:f86/64 scope link
       valid_lft forever preferred_lft forever
12: vxlan-6784: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 65485 qdisc noqueue master datapath state UNKNOWN group default qlen 1000
    link/ether e6:c9:f2:9c:c4:10 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::e4c9:f2ff:fe9c:c410/64 scope link
       valid_lft forever preferred_lft forever
14: vethweplab15bb5@if13: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master weave state UP group default
    link/ether aa:e1:9b:8c:4a:1a brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet6 fe80::a8e1:9bff:fe8c:4a1a/64 scope link
       valid_lft forever preferred_lft forever
root@k001:~# iptables-save
# Generated by iptables-save v1.6.0 on Tue Feb 27 19:36:48 2018
*nat
:PREROUTING ACCEPT [0:0]
:INPUT ACCEPT [0:0]
:OUTPUT ACCEPT [10:600]
:POSTROUTING ACCEPT [10:600]
:DOCKER - [0:0]
:KUBE-MARK-DROP - [0:0]
:KUBE-MARK-MASQ - [0:0]
:KUBE-NODEPORTS - [0:0]
:KUBE-POSTROUTING - [0:0]
:KUBE-SEP-ES652KEXJGQ2TLCD - [0:0]
:KUBE-SEP-F7D3EGXH6GIY237U - [0:0]
:KUBE-SEP-ZT5TVM6PMFDFQAMO - [0:0]
:KUBE-SERVICES - [0:0]
:KUBE-SVC-ERIFXISQEP7F7OF4 - [0:0]
:KUBE-SVC-NPX46M4PTMTKRN6Y - [0:0]
:KUBE-SVC-TCOU7JCQXEZGVUNU - [0:0]
:WEAVE - [0:0]
-A PREROUTING -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
-A OUTPUT -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER
-A POSTROUTING -m comment --comment "kubernetes postrouting rules" -j KUBE-POSTROUTING
-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
-A POSTROUTING -j WEAVE
-A DOCKER -i docker0 -j RETURN
-A KUBE-MARK-DROP -j MARK --set-xmark 0x8000/0x8000
-A KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000
-A KUBE-POSTROUTING -m comment --comment "kubernetes service traffic requiring SNAT" -m mark --mark 0x4000/0x4000 -j MASQUERADE
-A KUBE-SEP-ES652KEXJGQ2TLCD -s 10.32.0.4/32 -m comment --comment "kube-system/kube-dns:dns" -j KUBE-MARK-MASQ
-A KUBE-SEP-ES652KEXJGQ2TLCD -p udp -m comment --comment "kube-system/kube-dns:dns" -m udp -j DNAT --to-destination 10.32.0.4:53
-A KUBE-SEP-F7D3EGXH6GIY237U -s 10.1.0.204/32 -m comment --comment "default/kubernetes:https" -j KUBE-MARK-MASQ
-A KUBE-SEP-F7D3EGXH6GIY237U -p tcp -m comment --comment "default/kubernetes:https" -m recent --set --name KUBE-SEP-F7D3EGXH6GIY237U --mask 255.255.255.255 --rsource -m tcp -j DNAT --to-destination 10.1.0.204:6443
-A KUBE-SEP-ZT5TVM6PMFDFQAMO -s 10.32.0.4/32 -m comment --comment "kube-system/kube-dns:dns-tcp" -j KUBE-MARK-MASQ
-A KUBE-SEP-ZT5TVM6PMFDFQAMO -p tcp -m comment --comment "kube-system/kube-dns:dns-tcp" -m tcp -j DNAT --to-destination 10.32.0.4:53
-A KUBE-SERVICES -d 10.96.0.10/32 -p tcp -m comment --comment "kube-system/kube-dns:dns-tcp cluster IP" -m tcp --dport 53 -j KUBE-SVC-ERIFXISQEP7F7OF4
-A KUBE-SERVICES -d 10.96.0.1/32 -p tcp -m comment --comment "default/kubernetes:https cluster IP" -m tcp --dport 443 -j KUBE-SVC-NPX46M4PTMTKRN6Y
-A KUBE-SERVICES -d 10.96.0.10/32 -p udp -m comment --comment "kube-system/kube-dns:dns cluster IP" -m udp --dport 53 -j KUBE-SVC-TCOU7JCQXEZGVUNU
-A KUBE-SERVICES -m comment --comment "kubernetes service nodeports; NOTE: this must be the last rule in this chain" -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS
-A KUBE-SVC-ERIFXISQEP7F7OF4 -m comment --comment "kube-system/kube-dns:dns-tcp" -j KUBE-SEP-ZT5TVM6PMFDFQAMO
-A KUBE-SVC-NPX46M4PTMTKRN6Y -m comment --comment "default/kubernetes:https" -m recent --rcheck --seconds 10800 --reap --name KUBE-SEP-F7D3EGXH6GIY237U --mask 255.255.255.255 --rsource -j KUBE-SEP-F7D3EGXH6GIY237U
-A KUBE-SVC-NPX46M4PTMTKRN6Y -m comment --comment "default/kubernetes:https" -j KUBE-SEP-F7D3EGXH6GIY237U
-A KUBE-SVC-TCOU7JCQXEZGVUNU -m comment --comment "kube-system/kube-dns:dns" -j KUBE-SEP-ES652KEXJGQ2TLCD
-A WEAVE -s 10.32.0.0/12 -d 224.0.0.0/4 -j RETURN
-A WEAVE ! -s 10.32.0.0/12 -d 10.32.0.0/12 -j MASQUERADE
-A WEAVE -s 10.32.0.0/12 ! -d 10.32.0.0/12 -j MASQUERADE
COMMIT
# Completed on Tue Feb 27 19:36:48 2018
# Generated by iptables-save v1.6.0 on Tue Feb 27 19:36:48 2018
*filter
:INPUT ACCEPT [810:170978]
:FORWARD DROP [0:0]
:OUTPUT ACCEPT [799:194263]
:DOCKER - [0:0]
:DOCKER-ISOLATION - [0:0]
:KUBE-FIREWALL - [0:0]
:KUBE-FORWARD - [0:0]
:KUBE-SERVICES - [0:0]
:WEAVE-NPC - [0:0]
:WEAVE-NPC-DEFAULT - [0:0]
:WEAVE-NPC-INGRESS - [0:0]
-A INPUT -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A INPUT -j KUBE-FIREWALL
-A FORWARD -o weave -m comment --comment "NOTE: this must go before \'-j KUBE-FORWARD\'" -j WEAVE-NPC
-A FORWARD -o weave -m state --state NEW -j NFLOG --nflog-group 86
-A FORWARD -o weave -j DROP
-A FORWARD -i weave ! -o weave -j ACCEPT
-A FORWARD -o weave -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -m comment --comment "kubernetes forward rules" -j KUBE-FORWARD
-A FORWARD -j DOCKER-ISOLATION
-A FORWARD -o docker0 -j DOCKER
-A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -i docker0 ! -o docker0 -j ACCEPT
-A FORWARD -i docker0 -o docker0 -j ACCEPT
-A OUTPUT -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A OUTPUT -j KUBE-FIREWALL
-A DOCKER-ISOLATION -j RETURN
-A KUBE-FIREWALL -m comment --comment "kubernetes firewall for dropping marked packets" -m mark --mark 0x8000/0x8000 -j DROP
-A KUBE-FORWARD -m comment --comment "kubernetes forwarding rules" -m mark --mark 0x4000/0x4000 -j ACCEPT
-A WEAVE-NPC -m state --state RELATED,ESTABLISHED -j ACCEPT
-A WEAVE-NPC -d 224.0.0.0/4 -j ACCEPT
-A WEAVE-NPC -m state --state NEW -j WEAVE-NPC-DEFAULT
-A WEAVE-NPC -m state --state NEW -j WEAVE-NPC-INGRESS
-A WEAVE-NPC -m set ! --match-set weave-local-pods dst -j ACCEPT
-A WEAVE-NPC-DEFAULT -m set --match-set weave-E.1.0W^NGSp]0_t5WwH/]gX@L dst -m comment --comment "DefaultAllow isolation for namespace: default" -j ACCEPT
-A WEAVE-NPC-DEFAULT -m set --match-set weave-0EHD/vdN#O4]V?o4Tx7kS;APH dst -m comment --comment "DefaultAllow isolation for namespace: kube-public" -j ACCEPT
-A WEAVE-NPC-DEFAULT -m set --match-set weave-?b%zl9GIe0AET1(QI^7NWe*fO dst -m comment --comment "DefaultAllow isolation for namespace: kube-system" -j ACCEPT
COMMIT
# Completed on Tue Feb 27 19:36:48 2018

root@k002:~# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: ens33: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 00:0c:29:1b:e1:ab brd ff:ff:ff:ff:ff:ff
    inet 10.1.0.205/24 brd 10.1.0.255 scope global ens33
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:fe1b:e1ab/64 scope link
       valid_lft forever preferred_lft forever
3: ens34: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 00:0c:29:1b:e1:b5 brd ff:ff:ff:ff:ff:ff
    inet 20.1.0.159/24 brd 20.1.0.255 scope global ens34
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:fe1b:e1b5/64 scope link
       valid_lft forever preferred_lft forever
4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default
    link/ether 02:42:3e:b9:40:fe brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 scope global docker0
       valid_lft forever preferred_lft forever
5: datapath: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue state UNKNOWN group default qlen 1
    link/ether 9e:76:4f:74:8d:80 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::9c76:4fff:fe74:8d80/64 scope link
       valid_lft forever preferred_lft forever
7: weave: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue state UP group default qlen 1000
    link/ether 3a:52:22:3e:7d:1e brd ff:ff:ff:ff:ff:ff
    inet 10.44.0.0/12 brd 10.47.255.255 scope global weave
       valid_lft forever preferred_lft forever
    inet6 fe80::3852:22ff:fe3e:7d1e/64 scope link
       valid_lft forever preferred_lft forever
8: dummy0: <BROADCAST,NOARP> mtu 1500 qdisc noop state DOWN group default qlen 1000
    link/ether 0a:25:14:e2:d8:e9 brd ff:ff:ff:ff:ff:ff
10: vethwe-datapath@vethwe-bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master datapath state UP group default
    link/ether 1a:54:8a:af:2a:eb brd ff:ff:ff:ff:ff:ff
    inet6 fe80::1854:8aff:feaf:2aeb/64 scope link
       valid_lft forever preferred_lft forever
11: vethwe-bridge@vethwe-datapath: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master weave state UP group default
    link/ether b2:00:85:bc:9b:e7 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::b000:85ff:febc:9be7/64 scope link
       valid_lft forever preferred_lft forever
12: vxlan-6784: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 65485 qdisc noqueue master datapath state UNKNOWN group default qlen 1000
    link/ether ca:1c:c6:f6:db:80 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::c81c:c6ff:fef6:db80/64 scope link
       valid_lft forever preferred_lft forever
14: vethwepl942a7df@if13: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master weave state UP group default
    link/ether 8a:77:ef:f4:ad:37 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet6 fe80::8877:efff:fef4:ad37/64 scope link
       valid_lft forever preferred_lft forever

root@k002:~# iptables-save
# Generated by iptables-save v1.6.0 on Tue Feb 27 19:57:13 2018
*nat
:PREROUTING ACCEPT [0:0]
:INPUT ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
:POSTROUTING ACCEPT [0:0]
:DOCKER - [0:0]
:KUBE-MARK-DROP - [0:0]
:KUBE-MARK-MASQ - [0:0]
:KUBE-NODEPORTS - [0:0]
:KUBE-POSTROUTING - [0:0]
:KUBE-SEP-ES652KEXJGQ2TLCD - [0:0]
:KUBE-SEP-F7D3EGXH6GIY237U - [0:0]
:KUBE-SEP-ZT5TVM6PMFDFQAMO - [0:0]
:KUBE-SERVICES - [0:0]
:KUBE-SVC-ERIFXISQEP7F7OF4 - [0:0]
:KUBE-SVC-NPX46M4PTMTKRN6Y - [0:0]
:KUBE-SVC-TCOU7JCQXEZGVUNU - [0:0]
:WEAVE - [0:0]
-A PREROUTING -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
-A OUTPUT -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER
-A POSTROUTING -m comment --comment "kubernetes postrouting rules" -j KUBE-POSTROUTING
-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
-A POSTROUTING -j WEAVE
-A DOCKER -i docker0 -j RETURN
-A KUBE-MARK-DROP -j MARK --set-xmark 0x8000/0x8000
-A KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000
-A KUBE-POSTROUTING -m comment --comment "kubernetes service traffic requiring SNAT" -m mark --mark 0x4000/0x4000 -j MASQUERADE
-A KUBE-SEP-ES652KEXJGQ2TLCD -s 10.32.0.4/32 -m comment --comment "kube-system/kube-dns:dns" -j KUBE-MARK-MASQ
-A KUBE-SEP-ES652KEXJGQ2TLCD -p udp -m comment --comment "kube-system/kube-dns:dns" -m udp -j DNAT --to-destination 10.32.0.4:53
-A KUBE-SEP-F7D3EGXH6GIY237U -s 10.1.0.204/32 -m comment --comment "default/kubernetes:https" -j KUBE-MARK-MASQ
-A KUBE-SEP-F7D3EGXH6GIY237U -p tcp -m comment --comment "default/kubernetes:https" -m recent --set --name KUBE-SEP-F7D3EGXH6GIY237U --mask 255.255.255.255 --rsource -m tcp -j DNAT --to-destination 10.1.0.204:6443
-A KUBE-SEP-ZT5TVM6PMFDFQAMO -s 10.32.0.4/32 -m comment --comment "kube-system/kube-dns:dns-tcp" -j KUBE-MARK-MASQ
-A KUBE-SEP-ZT5TVM6PMFDFQAMO -p tcp -m comment --comment "kube-system/kube-dns:dns-tcp" -m tcp -j DNAT --to-destination 10.32.0.4:53
-A KUBE-SERVICES -d 10.96.0.10/32 -p udp -m comment --comment "kube-system/kube-dns:dns cluster IP" -m udp --dport 53 -j KUBE-SVC-TCOU7JCQXEZGVUNU
-A KUBE-SERVICES -d 10.96.0.10/32 -p tcp -m comment --comment "kube-system/kube-dns:dns-tcp cluster IP" -m tcp --dport 53 -j KUBE-SVC-ERIFXISQEP7F7OF4
-A KUBE-SERVICES -d 10.96.0.1/32 -p tcp -m comment --comment "default/kubernetes:https cluster IP" -m tcp --dport 443 -j KUBE-SVC-NPX46M4PTMTKRN6Y
-A KUBE-SERVICES -m comment --comment "kubernetes service nodeports; NOTE: this must be the last rule in this chain" -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS
-A KUBE-SVC-ERIFXISQEP7F7OF4 -m comment --comment "kube-system/kube-dns:dns-tcp" -j KUBE-SEP-ZT5TVM6PMFDFQAMO
-A KUBE-SVC-NPX46M4PTMTKRN6Y -m comment --comment "default/kubernetes:https" -m recent --rcheck --seconds 10800 --reap --name KUBE-SEP-F7D3EGXH6GIY237U --mask 255.255.255.255 --rsource -j KUBE-SEP-F7D3EGXH6GIY237U
-A KUBE-SVC-NPX46M4PTMTKRN6Y -m comment --comment "default/kubernetes:https" -j KUBE-SEP-F7D3EGXH6GIY237U
-A KUBE-SVC-TCOU7JCQXEZGVUNU -m comment --comment "kube-system/kube-dns:dns" -j KUBE-SEP-ES652KEXJGQ2TLCD
-A WEAVE -s 10.32.0.0/12 -d 224.0.0.0/4 -j RETURN
-A WEAVE ! -s 10.32.0.0/12 -d 10.32.0.0/12 -j MASQUERADE
-A WEAVE -s 10.32.0.0/12 ! -d 10.32.0.0/12 -j MASQUERADE
COMMIT
# Completed on Tue Feb 27 19:57:13 2018
# Generated by iptables-save v1.6.0 on Tue Feb 27 19:57:13 2018
*filter
:INPUT ACCEPT [56:14812]
:FORWARD DROP [0:0]
:OUTPUT ACCEPT [39:5192]
:DOCKER - [0:0]
:DOCKER-ISOLATION - [0:0]
:KUBE-FIREWALL - [0:0]
:KUBE-FORWARD - [0:0]
:KUBE-SERVICES - [0:0]
:WEAVE-NPC - [0:0]
:WEAVE-NPC-DEFAULT - [0:0]
:WEAVE-NPC-INGRESS - [0:0]
-A INPUT -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A INPUT -j KUBE-FIREWALL
-A FORWARD -o weave -m comment --comment "NOTE: this must go before \'-j KUBE-FORWARD\'" -j WEAVE-NPC
-A FORWARD -o weave -m state --state NEW -j NFLOG --nflog-group 86
-A FORWARD -o weave -j DROP
-A FORWARD -i weave ! -o weave -j ACCEPT
-A FORWARD -o weave -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -m comment --comment "kubernetes forward rules" -j KUBE-FORWARD
-A FORWARD -j DOCKER-ISOLATION
-A FORWARD -o docker0 -j DOCKER
-A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -i docker0 ! -o docker0 -j ACCEPT
-A FORWARD -i docker0 -o docker0 -j ACCEPT
-A OUTPUT -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A OUTPUT -j KUBE-FIREWALL
-A DOCKER-ISOLATION -j RETURN
-A KUBE-FIREWALL -m comment --comment "kubernetes firewall for dropping marked packets" -m mark --mark 0x8000/0x8000 -j DROP
-A KUBE-FORWARD -m comment --comment "kubernetes forwarding rules" -m mark --mark 0x4000/0x4000 -j ACCEPT
-A WEAVE-NPC -m state --state RELATED,ESTABLISHED -j ACCEPT
-A WEAVE-NPC -d 224.0.0.0/4 -j ACCEPT
-A WEAVE-NPC -m state --state NEW -j WEAVE-NPC-DEFAULT
-A WEAVE-NPC -m state --state NEW -j WEAVE-NPC-INGRESS
-A WEAVE-NPC -m set ! --match-set weave-local-pods dst -j ACCEPT
-A WEAVE-NPC-DEFAULT -m set --match-set weave-E.1.0W^NGSp]0_t5WwH/]gX@L dst -m comment --comment "DefaultAllow isolation for namespace: default" -j ACCEPT
-A WEAVE-NPC-DEFAULT -m set --match-set weave-0EHD/vdN#O4]V?o4Tx7kS;APH dst -m comment --comment "DefaultAllow isolation for namespace: kube-public" -j ACCEPT
-A WEAVE-NPC-DEFAULT -m set --match-set weave-?b%zl9GIe0AET1(QI^7NWe*fO dst -m comment --comment "DefaultAllow isolation for namespace: kube-system" -j ACCEPT
COMMIT
# Completed on Tue Feb 27 19:57:13 2018
root@k002:~#

root@k003:~# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: ens33: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 00:0c:29:6d:a0:c6 brd ff:ff:ff:ff:ff:ff
    inet 10.1.0.206/24 brd 10.1.0.255 scope global ens33
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:fe6d:a0c6/64 scope link
       valid_lft forever preferred_lft forever
3: ens34: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 00:0c:29:6d:a0:d0 brd ff:ff:ff:ff:ff:ff
    inet 20.1.0.160/24 brd 20.1.0.255 scope global ens34
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:fe6d:a0d0/64 scope link
       valid_lft forever preferred_lft forever
4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default
    link/ether 02:42:15:73:93:91 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 scope global docker0
       valid_lft forever preferred_lft forever
5: datapath: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue state UNKNOWN group default qlen 1
    link/ether ee:75:14:c4:31:19 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::ec75:14ff:fec4:3119/64 scope link
       valid_lft forever preferred_lft forever
7: weave: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue state UP group default qlen 1000
    link/ether 16:b1:25:6e:54:9f brd ff:ff:ff:ff:ff:ff
    inet 10.36.0.0/12 brd 10.47.255.255 scope global weave
       valid_lft forever preferred_lft forever
    inet6 fe80::14b1:25ff:fe6e:549f/64 scope link
       valid_lft forever preferred_lft forever
8: dummy0: <BROADCAST,NOARP> mtu 1500 qdisc noop state DOWN group default qlen 1000
    link/ether ea:1e:bf:fe:b8:6a brd ff:ff:ff:ff:ff:ff
10: vethwe-datapath@vethwe-bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master datapath state UP group default
    link/ether da:5b:03:89:fd:cd brd ff:ff:ff:ff:ff:ff
    inet6 fe80::d85b:3ff:fe89:fdcd/64 scope link
       valid_lft forever preferred_lft forever
11: vethwe-bridge@vethwe-datapath: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master weave state UP group default
    link/ether 62:1f:c8:69:27:19 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::601f:c8ff:fe69:2719/64 scope link
       valid_lft forever preferred_lft forever
12: vxlan-6784: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 65485 qdisc noqueue master datapath state UNKNOWN group default qlen 1000
    link/ether 86:b7:84:a9:f2:21 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::84b7:84ff:fea9:f221/64 scope link
       valid_lft forever preferred_lft forever
14: vethwepl249fdbc@if13: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master weave state UP group default
    link/ether 1e:0c:38:ae:56:39 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet6 fe80::1c0c:38ff:feae:5639/64 scope link
       valid_lft forever preferred_lft forever
root@k003:~#
root@k003:~# iptables-save
# Generated by iptables-save v1.6.0 on Tue Feb 27 02:57:45 2018
*nat
:PREROUTING ACCEPT [0:0]
:INPUT ACCEPT [0:0]
:OUTPUT ACCEPT [1:60]
:POSTROUTING ACCEPT [1:60]
:DOCKER - [0:0]
:KUBE-MARK-DROP - [0:0]
:KUBE-MARK-MASQ - [0:0]
:KUBE-NODEPORTS - [0:0]
:KUBE-POSTROUTING - [0:0]
:KUBE-SEP-ES652KEXJGQ2TLCD - [0:0]
:KUBE-SEP-F7D3EGXH6GIY237U - [0:0]
:KUBE-SEP-ZT5TVM6PMFDFQAMO - [0:0]
:KUBE-SERVICES - [0:0]
:KUBE-SVC-ERIFXISQEP7F7OF4 - [0:0]
:KUBE-SVC-NPX46M4PTMTKRN6Y - [0:0]
:KUBE-SVC-TCOU7JCQXEZGVUNU - [0:0]
:WEAVE - [0:0]
-A PREROUTING -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
-A OUTPUT -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER
-A POSTROUTING -m comment --comment "kubernetes postrouting rules" -j KUBE-POSTROUTING
-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
-A POSTROUTING -j WEAVE
-A DOCKER -i docker0 -j RETURN
-A KUBE-MARK-DROP -j MARK --set-xmark 0x8000/0x8000
-A KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000
-A KUBE-POSTROUTING -m comment --comment "kubernetes service traffic requiring SNAT" -m mark --mark 0x4000/0x4000 -j MASQUERADE
-A KUBE-SEP-ES652KEXJGQ2TLCD -s 10.32.0.4/32 -m comment --comment "kube-system/kube-dns:dns" -j KUBE-MARK-MASQ
-A KUBE-SEP-ES652KEXJGQ2TLCD -p udp -m comment --comment "kube-system/kube-dns:dns" -m udp -j DNAT --to-destination 10.32.0.4:53
-A KUBE-SEP-F7D3EGXH6GIY237U -s 10.1.0.204/32 -m comment --comment "default/kubernetes:https" -j KUBE-MARK-MASQ
-A KUBE-SEP-F7D3EGXH6GIY237U -p tcp -m comment --comment "default/kubernetes:https" -m recent --set --name KUBE-SEP-F7D3EGXH6GIY237U --mask 255.255.255.255 --rsource -m tcp -j DNAT --to-destination 10.1.0.204:6443
-A KUBE-SEP-ZT5TVM6PMFDFQAMO -s 10.32.0.4/32 -m comment --comment "kube-system/kube-dns:dns-tcp" -j KUBE-MARK-MASQ
-A KUBE-SEP-ZT5TVM6PMFDFQAMO -p tcp -m comment --comment "kube-system/kube-dns:dns-tcp" -m tcp -j DNAT --to-destination 10.32.0.4:53
-A KUBE-SERVICES -d 10.96.0.1/32 -p tcp -m comment --comment "default/kubernetes:https cluster IP" -m tcp --dport 443 -j KUBE-SVC-NPX46M4PTMTKRN6Y
-A KUBE-SERVICES -d 10.96.0.10/32 -p udp -m comment --comment "kube-system/kube-dns:dns cluster IP" -m udp --dport 53 -j KUBE-SVC-TCOU7JCQXEZGVUNU
-A KUBE-SERVICES -d 10.96.0.10/32 -p tcp -m comment --comment "kube-system/kube-dns:dns-tcp cluster IP" -m tcp --dport 53 -j KUBE-SVC-ERIFXISQEP7F7OF4
-A KUBE-SERVICES -m comment --comment "kubernetes service nodeports; NOTE: this must be the last rule in this chain" -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS
-A KUBE-SVC-ERIFXISQEP7F7OF4 -m comment --comment "kube-system/kube-dns:dns-tcp" -j KUBE-SEP-ZT5TVM6PMFDFQAMO
-A KUBE-SVC-NPX46M4PTMTKRN6Y -m comment --comment "default/kubernetes:https" -m recent --rcheck --seconds 10800 --reap --name KUBE-SEP-F7D3EGXH6GIY237U --mask 255.255.255.255 --rsource -j KUBE-SEP-F7D3EGXH6GIY237U
-A KUBE-SVC-NPX46M4PTMTKRN6Y -m comment --comment "default/kubernetes:https" -j KUBE-SEP-F7D3EGXH6GIY237U
-A KUBE-SVC-TCOU7JCQXEZGVUNU -m comment --comment "kube-system/kube-dns:dns" -j KUBE-SEP-ES652KEXJGQ2TLCD
-A WEAVE -s 10.32.0.0/12 -d 224.0.0.0/4 -j RETURN
-A WEAVE ! -s 10.32.0.0/12 -d 10.32.0.0/12 -j MASQUERADE
-A WEAVE -s 10.32.0.0/12 ! -d 10.32.0.0/12 -j MASQUERADE
COMMIT
# Completed on Tue Feb 27 02:57:45 2018
# Generated by iptables-save v1.6.0 on Tue Feb 27 02:57:45 2018
*filter
:INPUT ACCEPT [73:18472]
:FORWARD DROP [0:0]
:OUTPUT ACCEPT [55:10877]
:DOCKER - [0:0]
:DOCKER-ISOLATION - [0:0]
:KUBE-FIREWALL - [0:0]
:KUBE-FORWARD - [0:0]
:KUBE-SERVICES - [0:0]
:WEAVE-NPC - [0:0]
:WEAVE-NPC-DEFAULT - [0:0]
:WEAVE-NPC-INGRESS - [0:0]
-A INPUT -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A INPUT -j KUBE-FIREWALL
-A FORWARD -o weave -m comment --comment "NOTE: this must go before \'-j KUBE-FORWARD\'" -j WEAVE-NPC
-A FORWARD -o weave -m state --state NEW -j NFLOG --nflog-group 86
-A FORWARD -o weave -j DROP
-A FORWARD -i weave ! -o weave -j ACCEPT
-A FORWARD -o weave -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -m comment --comment "kubernetes forward rules" -j KUBE-FORWARD
-A FORWARD -j DOCKER-ISOLATION
-A FORWARD -o docker0 -j DOCKER
-A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -i docker0 ! -o docker0 -j ACCEPT
-A FORWARD -i docker0 -o docker0 -j ACCEPT
-A OUTPUT -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A OUTPUT -j KUBE-FIREWALL
-A DOCKER-ISOLATION -j RETURN
-A KUBE-FIREWALL -m comment --comment "kubernetes firewall for dropping marked packets" -m mark --mark 0x8000/0x8000 -j DROP
-A KUBE-FORWARD -m comment --comment "kubernetes forwarding rules" -m mark --mark 0x4000/0x4000 -j ACCEPT
-A WEAVE-NPC -m state --state RELATED,ESTABLISHED -j ACCEPT
-A WEAVE-NPC -d 224.0.0.0/4 -j ACCEPT
-A WEAVE-NPC -m state --state NEW -j WEAVE-NPC-DEFAULT
-A WEAVE-NPC -m state --state NEW -j WEAVE-NPC-INGRESS
-A WEAVE-NPC -m set ! --match-set weave-local-pods dst -j ACCEPT
-A WEAVE-NPC-DEFAULT -m set --match-set weave-0EHD/vdN#O4]V?o4Tx7kS;APH dst -m comment --comment "DefaultAllow isolation for namespace: kube-public" -j ACCEPT
-A WEAVE-NPC-DEFAULT -m set --match-set weave-?b%zl9GIe0AET1(QI^7NWe*fO dst -m comment --comment "DefaultAllow isolation for namespace: kube-system" -j ACCEPT
-A WEAVE-NPC-DEFAULT -m set --match-set weave-E.1.0W^NGSp]0_t5WwH/]gX@L dst -m comment --comment "DefaultAllow isolation for namespace: default" -j ACCEPT
COMMIT
# Completed on Tue Feb 27 02:57:45 2018


root@k001:~# kubectl get nodes -o wide
NAME      STATUS    ROLES     AGE       VERSION   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME
k001      Ready     master    4h        v1.9.3    <none>        Ubuntu 16.04.4 LTS   4.4.0-116-generic   docker://1.13.1
k002      Ready     <none>    2h        v1.9.3    <none>        Ubuntu 16.04.4 LTS   4.4.0-116-generic   docker://1.13.1
k003      Ready     <none>    2h        v1.9.3    <none>        Ubuntu 16.04.4 LTS   4.4.0-116-generic   docker://1.13.1
root@k001:~# kubectl get po --all-namespaces -o wide
NAMESPACE     NAME                           READY     STATUS    RESTARTS   AGE       IP           NODE
default       iperfc-7f8bc954d5-tvdjg        1/1       Running   0          2h        10.44.0.1    k002
default       iperfs-5b784d89c-2sdmj         1/1       Running   0          2h        10.36.0.1    k003
kube-system   etcd-k001                      1/1       Running   1          4h        10.1.0.204   k001
kube-system   kube-apiserver-k001            1/1       Running   1          4h        10.1.0.204   k001
kube-system   kube-controller-manager-k001   1/1       Running   1          4h        10.1.0.204   k001
kube-system   kube-dns-6f4fd4bdf-92jvn       3/3       Running   3          4h        10.32.0.4    k001
kube-system   kube-proxy-59c66               1/1       Running   0          2h        10.1.0.206   k003
kube-system   kube-proxy-7qrc7               1/1       Running   1          4h        10.1.0.204   k001
kube-system   kube-proxy-smbkq               1/1       Running   0          2h        10.1.0.205   k002
kube-system   kube-scheduler-k001            1/1       Running   1          4h        10.1.0.204   k001
kube-system   weave-net-ck5tw                2/2       Running   1          2h        10.1.0.205   k002
kube-system   weave-net-jkjdv                2/2       Running   2          4h        10.1.0.204   k001
kube-system   weave-net-nflsp                2/2       Running   1          2h        10.1.0.206   k003




root@k001:~# ps -xf | more
   PID TTY      STAT   TIME COMMAND
  4376 pts/1    S      0:00 sudo -i
  4377 pts/1    S      0:00  \_ -bash
 11068 pts/1    Sl+    0:01      \_ kubectl exec -it iperfs-5b784d89c-2sdmj -- /bin/sh
  3444 pts/0    S      0:00 sudo -i
  3445 pts/0    S      0:00  \_ -bash
 22432 pts/0    R+     0:00      \_ ps -xf
 22433 pts/0    S+     0:00      \_ more
     2 ?        S      0:00 [kthreadd]
     3 ?        S      0:00  \_ [ksoftirqd/0]
     5 ?        S<     0:00  \_ [kworker/0:0H]
     7 ?        S      0:06  \_ [rcu_sched]
     8 ?        S      0:00  \_ [rcu_bh]
     9 ?        S      0:00  \_ [migration/0]
    10 ?        S      0:00  \_ [watchdog/0]
    11 ?        S      0:00  \_ [watchdog/1]
    12 ?        S      0:00  \_ [migration/1]
    13 ?        R      0:02  \_ [ksoftirqd/1]
    15 ?        S<     0:00  \_ [kworker/1:0H]
    16 ?        S      0:00  \_ [kdevtmpfs]
    17 ?        S<     0:00  \_ [netns]
    18 ?        S<     0:00  \_ [perf]
    19 ?        S      0:00  \_ [khungtaskd]
    20 ?        S<     0:00  \_ [writeback]
    21 ?        SN     0:00  \_ [ksmd]
    22 ?        SN     0:00  \_ [khugepaged]
    23 ?        S<     0:00  \_ [crypto]
    24 ?        S<     0:00  \_ [kintegrityd]
    25 ?        S<     0:00  \_ [bioset]
    26 ?        S<     0:00  \_ [kblockd]
    27 ?        S<     0:00  \_ [ata_sff]
    28 ?        S<     0:00  \_ [md]
    29 ?        S<     0:00  \_ [devfreq_wq]
    33 ?        S      0:00  \_ [kswapd0]
    34 ?        S<     0:00  \_ [vmstat]
    35 ?        S      0:00  \_ [fsnotify_mark]
    36 ?        S      0:00  \_ [ecryptfs-kthrea]
    52 ?        S<     0:00  \_ [kthrotld]
    54 ?        S<     0:00  \_ [acpi_thermal_pm]
    55 ?        S<     0:00  \_ [bioset]
    56 ?        S<     0:00  \_ [bioset]
    57 ?        S<     0:00  \_ [bioset]
    58 ?        S<     0:00  \_ [bioset]
    59 ?        S<     0:00  \_ [bioset]
    60 ?        S<     0:00  \_ [bioset]
    61 ?        S<     0:00  \_ [bioset]
    62 ?        S<     0:00  \_ [bioset]
    63 ?        S      0:00  \_ [scsi_eh_0]
    64 ?        S<     0:00  \_ [scsi_tmf_0]
    65 ?        S      0:00  \_ [scsi_eh_1]
    66 ?        S<     0:00  \_ [scsi_tmf_1]
    72 ?        S<     0:00  \_ [ipv6_addrconf]
    85 ?        S<     0:00  \_ [deferwq]
    86 ?        S<     0:00  \_ [charger_manager]
   136 ?        S<     0:00  \_ [bioset]
   137 ?        S<     0:00  \_ [bioset]
   138 ?        S<     0:00  \_ [bioset]
   139 ?        S<     0:00  \_ [bioset]
   140 ?        S<     0:00  \_ [bioset]
   141 ?        S<     0:00  \_ [bioset]
   142 ?        S<     0:00  \_ [bioset]
   143 ?        S<     0:00  \_ [bioset]
   145 ?        S      0:11  \_ [kworker/1:2]
   157 ?        S<     0:00  \_ [kpsmoused]
   158 ?        S<     0:00  \_ [mpt_poll_0]
   159 ?        S<     0:00  \_ [mpt/0]
   160 ?        S      0:00  \_ [scsi_eh_2]
   161 ?        S<     0:00  \_ [scsi_tmf_2]
   162 ?        S<     0:00  \_ [bioset]
   163 ?        S<     0:00  \_ [ttm_swap]
   189 ?        S      0:00  \_ [scsi_eh_3]
   190 ?        S<     0:00  \_ [scsi_tmf_3]
   191 ?        S      0:00  \_ [scsi_eh_4]
   192 ?        S<     0:00  \_ [scsi_tmf_4]
   193 ?        S      0:00  \_ [scsi_eh_5]
   194 ?        S<     0:00  \_ [scsi_tmf_5]
   195 ?        S      0:00  \_ [scsi_eh_6]
   196 ?        S<     0:00  \_ [scsi_tmf_6]
   197 ?        S      0:00  \_ [scsi_eh_7]
   198 ?        S<     0:00  \_ [scsi_tmf_7]
   199 ?        S      0:00  \_ [scsi_eh_8]
   200 ?        S<     0:00  \_ [scsi_tmf_8]
   201 ?        S      0:00  \_ [scsi_eh_9]
   202 ?        S<     0:00  \_ [scsi_tmf_9]
   203 ?        S      0:00  \_ [scsi_eh_10]
   204 ?        S<     0:00  \_ [scsi_tmf_10]
   205 ?        S      0:00  \_ [scsi_eh_11]
   206 ?        S<     0:00  \_ [scsi_tmf_11]
   207 ?        S      0:00  \_ [scsi_eh_12]
   208 ?        S<     0:00  \_ [scsi_tmf_12]
   209 ?        S      0:00  \_ [scsi_eh_13]
   210 ?        S<     0:00  \_ [scsi_tmf_13]
   211 ?        S      0:00  \_ [scsi_eh_14]
   212 ?        S<     0:00  \_ [scsi_tmf_14]
   213 ?        S      0:00  \_ [scsi_eh_15]
   214 ?        S<     0:00  \_ [scsi_tmf_15]
   215 ?        S      0:00  \_ [scsi_eh_16]
   216 ?        S<     0:00  \_ [scsi_tmf_16]
   217 ?        S      0:00  \_ [scsi_eh_17]
   218 ?        S<     0:00  \_ [scsi_tmf_17]
   219 ?        S      0:00  \_ [scsi_eh_18]
   220 ?        S<     0:00  \_ [scsi_tmf_18]
   221 ?        S      0:00  \_ [scsi_eh_19]
   222 ?        S<     0:00  \_ [scsi_tmf_19]
   223 ?        S      0:00  \_ [scsi_eh_20]
   224 ?        S<     0:00  \_ [scsi_tmf_20]
   225 ?        S      0:00  \_ [scsi_eh_21]
   226 ?        S<     0:00  \_ [scsi_tmf_21]
   227 ?        S      0:00  \_ [scsi_eh_22]
   228 ?        S<     0:00  \_ [scsi_tmf_22]
   229 ?        S      0:00  \_ [scsi_eh_23]
   230 ?        S<     0:00  \_ [scsi_tmf_23]
   231 ?        S      0:00  \_ [scsi_eh_24]
   232 ?        S<     0:00  \_ [scsi_tmf_24]
   233 ?        S      0:00  \_ [scsi_eh_25]
   234 ?        S<     0:00  \_ [scsi_tmf_25]
   235 ?        S      0:00  \_ [scsi_eh_26]
   236 ?        S<     0:00  \_ [scsi_tmf_26]
   237 ?        S      0:00  \_ [scsi_eh_27]
   238 ?        S<     0:00  \_ [scsi_tmf_27]
   239 ?        S      0:00  \_ [scsi_eh_28]
   240 ?        S<     0:00  \_ [scsi_tmf_28]
   241 ?        S      0:00  \_ [scsi_eh_29]
   242 ?        S<     0:00  \_ [scsi_tmf_29]
   243 ?        S      0:00  \_ [scsi_eh_30]
   244 ?        S<     0:00  \_ [scsi_tmf_30]
   245 ?        S      0:00  \_ [scsi_eh_31]
   246 ?        S<     0:00  \_ [scsi_tmf_31]
   247 ?        S      0:00  \_ [scsi_eh_32]
   248 ?        S<     0:00  \_ [scsi_tmf_32]
   276 ?        S<     0:00  \_ [bioset]
   278 ?        S<     0:00  \_ [kworker/1:1H]
   312 ?        S      0:01  \_ [jbd2/sda1-8]
   313 ?        S<     0:00  \_ [ext4-rsv-conver]
   351 ?        S      0:00  \_ [kworker/0:5]
   360 ?        S      0:00  \_ [kworker/1:3]
   366 ?        S      0:00  \_ [kauditd]
   728 ?        S<     0:00  \_ [kworker/0:1H]
   743 ?        S<     0:00  \_ [kworker/u257:0]
   744 ?        S<     0:00  \_ [hci0]
   745 ?        S<     0:00  \_ [hci0]
   748 ?        S<     0:00  \_ [kworker/u257:2]
  5911 ?        S      0:10  \_ [kworker/0:1]
 17217 ?        S      0:00  \_ [kworker/u256:0]
 21354 ?        S      0:00  \_ [kworker/u256:1]
     1 ?        Ss     0:03 /sbin/init noprompt
   354 ?        Ss     0:00 /lib/systemd/systemd-journald
   400 ?        Ss     0:01 /lib/systemd/systemd-udevd
  1125 ?        Ss     0:00 /sbin/dhclient -1 -v -pf /run/dhclient.ens34.pid -lf /var/lib/dhcp/dhclient.ens34.leases -I -df /var/lib/dhcp/dhclient6.ens34.leases ens34
  1284 ?        Ssl    0:00 /usr/sbin/vmware-vmblock-fuse -o subtype=vmware-vmblock,default_permissions,allow_other /var/run/vmblock-fuse
  1303 ?        S      0:11 /usr/sbin/vmtoolsd
  1321 ?        Ss     0:00 /usr/sbin/cron -f
  1336 ?        Ss     0:00 /lib/systemd/systemd-logind
  1350 ?        Ss     0:00 /usr/sbin/sshd -D
  3408 ?        Ss     0:00  \_ sshd: color [priv]
  4345 ?        Ss     0:00  \_ sshd: color [priv]
  1352 ?        Ssl    0:00 /usr/lib/accountsservice/accounts-daemon
  1397 ?        Ssl    1:48 /usr/bin/dockerd -H fd://
  1455 ?        Ssl    0:11  \_ containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --shim containerd-shim --runtime runc --runtime-args --systemd-cgroup=true
  1683 ?        Sl     0:00      \_ containerd-shim f04bbbd4ecd57656e43f1fd4b47e1027cefe57542bf4997d647669be9b790f15 /var/run/docker/libcontainerd/f04bbbd4ecd57656e43f1fd4b47e1027cefe57542bf4997d647669be9b790f15 runc
  1770 ?        Ss     0:00      |   \_ /pause
  1689 ?        Sl     0:00      \_ containerd-shim 7b5be3bcfa807c0960c40d7890f376017da681114816dc71d8e4a824b1b97d1e /var/run/docker/libcontainerd/7b5be3bcfa807c0960c40d7890f376017da681114816dc71d8e4a824b1b97d1e runc
  1769 ?        Ss     0:00      |   \_ /pause
  1690 ?        Sl     0:00      \_ containerd-shim 7dfc6be1ccf22b669350f98c57f218036ebebddf14214a73210eb8b8b530b13b /var/run/docker/libcontainerd/7dfc6be1ccf22b669350f98c57f218036ebebddf14214a73210eb8b8b530b13b runc
  1762 ?        Ss     0:00      |   \_ /pause
  1691 ?        Sl     0:00      \_ containerd-shim 6acd22db26914409da854455fd2fd1727b31064f9562306a97c3b11088127c62 /var/run/docker/libcontainerd/6acd22db26914409da854455fd2fd1727b31064f9562306a97c3b11088127c62 runc
  1757 ?        Ss     0:00      |   \_ /pause
  1816 ?        Sl     0:00      \_ containerd-shim 05a5f0c006eeba5b6d9a3dbd2d337259ef9c75a62694613d4e55a1454ad89217 /var/run/docker/libcontainerd/05a5f0c006eeba5b6d9a3dbd2d337259ef9c75a62694613d4e55a1454ad89217 runc
  1845 ?        Ssl    2:12      |   \_ etcd --listen-client-urls=http://127.0.0.1:2379 --advertise-client-urls=http://127.0.0.1:2379 --data-dir=/var/lib/etcd
  1842 ?        Sl     0:00      \_ containerd-shim fd2394f861a0672244c1ebdf80bff65107f00a55f3262e7c69a78250ed05f67d /var/run/docker/libcontainerd/fd2394f861a0672244c1ebdf80bff65107f00a55f3262e7c69a78250ed05f67d runc
  1872 ?        Ssl    1:47      |   \_ kube-scheduler --address=127.0.0.1 --leader-elect=true --kubeconfig=/etc/kubernetes/scheduler.conf
  1880 ?        Sl     0:01      \_ containerd-shim fb64fa496160e237db835fc24e3d6e1d3426d6f37574833ad1596b4ea5e82212 /var/run/docker/libcontainerd/fb64fa496160e237db835fc24e3d6e1d3426d6f37574833ad1596b4ea5e82212 runc
  1926 ?        Ssl    6:40      |   \_ kube-apiserver --requestheader-extra-headers-prefix=X-Remote-Extra- --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --insecure-port=0 --requestheader-username-headers=X-Remote-User --advertise-address=10.1.0.204 --service-
cluster-ip-range=10.96.0.0/12 --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --admission-control=Initializers,NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota --allow-privileged=true --requestheader-group-headers=X-Remote-Group --reques
theader-allowed-names=front-proxy-client --tls-private-key-file=/etc/kubernetes/pki/apiserver.key --secure-port=6443 --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --enable-bootstrap-token-auth=true --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --kubelet-client-certificate=/etc/kubernetes/p
ki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --service-account-key-file=/etc/kubernetes/pki/sa.pub --client-ca-file=/etc/kubernetes/pki/ca.crt --authorization-mode=Node,RBAC --etcd-servers=http://127.0.0.1:2379
  1890 ?        Sl     0:00      \_ containerd-shim 5d544766a8da9d678dc2906f38672c31120f4f3b848db22ca2745b5a72665520 /var/run/docker/libcontainerd/5d544766a8da9d678dc2906f38672c31120f4f3b848db22ca2745b5a72665520 runc
  1941 ?        Ssl    6:47      |   \_ kube-controller-manager --address=127.0.0.1 --leader-elect=true --kubeconfig=/etc/kubernetes/controller-manager.conf --service-account-private-key-file=/etc/kubernetes/pki/sa.key --use-service-account-credentials=true --controllers=*,bootstrapsigner,tokencleaner --root-ca-file=/etc/kubernet
es/pki/ca.crt --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
  2002 ?        Sl     0:00      \_ containerd-shim 98608179c21da8132ee4a040a2ecfe3fe0d7b6b5a309765a7720ddc2c0e15056 /var/run/docker/libcontainerd/98608179c21da8132ee4a040a2ecfe3fe0d7b6b5a309765a7720ddc2c0e15056 runc
  2032 ?        Ss     0:00      |   \_ /pause
  2022 ?        Sl     0:00      \_ containerd-shim 2f6c425cf25fa72fe206930ec0d136592bda88fab1dbe15b2592d4283ef7e82e /var/run/docker/libcontainerd/2f6c425cf25fa72fe206930ec0d136592bda88fab1dbe15b2592d4283ef7e82e runc
  2049 ?        Ss     0:00      |   \_ /pause
  2077 ?        Sl     0:00      \_ containerd-shim eec0d266e77ffb6f96269b58d9146c1bf28a98e5b4187a1c053494941bdad760 /var/run/docker/libcontainerd/eec0d266e77ffb6f96269b58d9146c1bf28a98e5b4187a1c053494941bdad760 runc
  2095 ?        Ss     0:00      |   \_ /bin/sh /home/weave/launch.sh
  2800 ?        Sl     0:08      |       \_ /home/weave/weaver --port=6783 --datapath=datapath --name=a6:71:1b:65:6b:81 --host-root=/host --http-addr=127.0.0.1:6784 --status-addr=0.0.0.0:6782 --docker-api= --no-dns --db-prefix=/weavedb/weave-net --ipalloc-range=10.32.0.0/12 --nickname=k001 --ipalloc-init consensus=1 --conn-limit=
30 --expect-npc 10.1.0.204
  2102 ?        Sl     0:00      \_ containerd-shim 7235931cce0dd3228837975a7cbdd47d72e3110afba34010f1b6dd5779f40816 /var/run/docker/libcontainerd/7235931cce0dd3228837975a7cbdd47d72e3110afba34010f1b6dd5779f40816 runc
  2123 ?        Ssl    0:29      |   \_ /usr/local/bin/kube-proxy --config=/var/lib/kube-proxy/config.conf
  2184 ?        Sl     0:00      \_ containerd-shim 8119da50fcb71b0122e1dd8691bc63416386b079662ca45cee848359590ea141 /var/run/docker/libcontainerd/8119da50fcb71b0122e1dd8691bc63416386b079662ca45cee848359590ea141 runc
  2208 ?        Ssl    0:01      |   \_ /usr/bin/weave-npc
  2459 ?        S<     0:00      |       \_ /usr/sbin/ulogd -v
  3073 ?        Sl     0:00      \_ containerd-shim ab15bb529dfc0c51d5cf261a2e03dc57e858010efa83d60e393480750002a377 /var/run/docker/libcontainerd/ab15bb529dfc0c51d5cf261a2e03dc57e858010efa83d60e393480750002a377 runc
  3091 ?        Ss     0:00      |   \_ /pause
  3272 ?        Sl     0:00      \_ containerd-shim 4aa372e8a68c6a0a068a5ca8b157d011365ef23bff52797ac10944def0ec0c2c /var/run/docker/libcontainerd/4aa372e8a68c6a0a068a5ca8b157d011365ef23bff52797ac10944def0ec0c2c runc
  3290 ?        Ssl    0:08      |   \_ /kube-dns --domain=cluster.local. --dns-port=10053 --config-dir=/kube-dns-config --v=2
  3304 ?        Sl     0:00      \_ containerd-shim 3d3e6850dcc6e01fd055ac2cc8ca5a608fe78a5749734d334c80c7bc6b53051b /var/run/docker/libcontainerd/3d3e6850dcc6e01fd055ac2cc8ca5a608fe78a5749734d334c80c7bc6b53051b runc
  3324 ?        Ssl    0:00      |   \_ /dnsmasq-nanny -v=2 -logtostderr -configDir=/etc/k8s/dns/dnsmasq-nanny -restartDnsmasq=true -- -k --cache-size=1000 --no-negcache --log-facility=- --server=/cluster.local/127.0.0.1#10053 --server=/in-addr.arpa/127.0.0.1#10053 --server=/ip6.arpa/127.0.0.1#10053
  3390 ?        S      0:01      |       \_ /usr/sbin/dnsmasq -k --cache-size=1000 --no-negcache --log-facility=- --server=/cluster.local/127.0.0.1#10053 --server=/in-addr.arpa/127.0.0.1#10053 --server=/ip6.arpa/127.0.0.1#10053
  3343 ?        Sl     0:00      \_ containerd-shim 79499fc37e85036ca8b1aa093c2c3a3348a2e781bea4dc1b214cdd29388dd21c /var/run/docker/libcontainerd/79499fc37e85036ca8b1aa093c2c3a3348a2e781bea4dc1b214cdd29388dd21c runc
  1422 tty1     Ss+    0:00 /sbin/agetty --noclear tty1 linux
  1426 ?        Ss     0:00 /usr/sbin/irqbalance --pid=/var/run/irqbalance.pid
  3834 ?        Ssl    6:43 /usr/bin/kubelet --kubeconfig=/etc/kubernetes/kubelet.conf --pod-manifest-path=/etc/kubernetes/manifests --allow-privileged=true --network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin --cluster-dns=10.96.0.10 --cluster-domain=cluster.local --authorization-mode=Webhook --client-ca
-file=/etc/kubernetes/pki/ca.crt --cadvisor-port=0 --rotate-certificates=true --cert-dir=/var/lib/kubelet/pki --fail-swap-on=false --cgroup-driver=systemd
root@k001:~#

