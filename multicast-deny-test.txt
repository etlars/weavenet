(1) 참고사이트들
https://kubernetes.io/docs/tasks/administer-cluster/declare-network-policy/
https://github.com/ahmetb/kubernetes-network-policy-recipes/blob/master/04-deny-traffic-from-other-namespaces.md
https://www.weave.works/docs/net/latest/kubernetes/kube-addon/#npc
https://store.docker.com/community/images/greenpau/mtools
https://github.com/c4po/multicast-test  <-- python code를 뽑아온곳임. 


(2) multicast traffic을 만들수 있는 docker image를 찾아서...
많이 찾아봤지만... crashimage... 오류로 실패.
그중에 하나 찾은거는 mjelen/demo-multicast
그런데 사용법은 없고, 실행파일 2개있는데 어떻게 쓰는지 찾기... 귀찮고... 다행이 python이 실행된다. 
아래 python code 2개를 집어넣음.
[recv.py]
import socket
import struct

MCAST_GRP = '224.1.1.1'
MCAST_PORT = 5007

sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
sock.bind((MCAST_GRP, MCAST_PORT))
mreq = struct.pack("4sl", socket.inet_aton(MCAST_GRP), socket.INADDR_ANY)

sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)

while True:
  print sock.recv(10240)


[send.py]
import socket

MCAST_GRP = '224.1.1.1'
MCAST_PORT = 5007

sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, 2)
sock.sendto("ping from: " + socket.gethostname(), (MCAST_GRP, MCAST_PORT))


이제 이넘들을 각각 실행해서 테스트해보니 multicast 된다~!

[root@mc1g-6f4bd8989c-lh749 ~]# python send.py

[root@mc1g-6f4bd8989c-zprdw ~]# python recv.py
ping from: mc1g-6f4bd8989c-lh749
[root@mc2g-6d4578df49-gz2df ~]# python recv.py
ping from: mc1g-6f4bd8989c-lh749


(3) 이제 다른 namespace에 집어넣자. 

kubectl run mc2 --image=mjelen/demo-multicast --replicas=2
kubectl run mc1 --image=mjelen/demo-multicast --replicas=2

4개의 pod가 생성되고... 
root@k001:~/work# kubectl get po -o wide --all-namespaces | grep group
mc1group      deploy-test-1-8646c8d498-qnqg6          1/1       Running   0          14m       10.44.0.16   k002
mc1group      mc1g-6f4bd8989c-lh749                   1/1       Running   0          55m       10.44.0.14   k002
mc1group      mc1g-6f4bd8989c-zprdw                   1/1       Running   0          55m       10.36.0.7    k003
mc2group      deploy-test-1-8646c8d498-8nq59          1/1       Running   0          14m       10.44.0.17   k002
mc2group      mc2g-6d4578df49-5m976                   1/1       Running   0          57m       10.36.0.8    k003
mc2group      mc2g-6d4578df49-gz2df                   1/1       Running   0          57m       10.44.0.15   k002

4번씩 recv.py, send.py파일을 복사해넣음 ㅠ.ㅠ;;
kubectl exec -it mc1g-6f4bd8989c-lh749 -n mc1group -- /bin/bash
kubectl exec -it mc1g-6f4bd8989c-zprdw -n mc1group -- /bin/bash
kubectl exec -it mc2g-6d4578df49-5m976 -n mc1group -- /bin/bash
kubectl exec -it mc2g-6d4578df49-gz2df -n mc1group -- /bin/bash


cross로 멀티캐스트해보면 mc1group namespace에 있는 pod나 mc2group namespace에 있는 pod 모두 join한다. 
이제 deny rule을 넣어보자...



(4) multicast traffic이 namespace별로 막히는지 준비작업

이제 namespace별로 막히는지 테스트를 위해 간단히 ping, http먼저 해보기로함. 

ping은 그냥하면 되고... web은 calico 테스트에서 사용했던거 빌려옴.
root@k001:~/work# cat tiny-web.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: deploy-test-1
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: web-front-end
        version: v1
    spec:
      containers:
      - name: tiny-web-server-1
        image: jonlangemak/web1_8080
        ports:
        - containerPort: 8080
          name: web-port
          protocol: TCP
root@k001:~/work# kubectl create -f tiny-web.yaml -n mc1group
root@k001:~/work# kubectl create -f tiny-web.yaml -n mc2group

root@k001:~/work# kubectl get po -o wide  --all-namespaces |  grep group
(가) mc1group      deploy-test-1-8646c8d498-qnqg6          1/1       Running   0          1h        10.44.0.16   k002
(나) mc1group      mc1g-6f4bd8989c-lh749                   1/1       Running   0          2h        10.44.0.14   k002
(다) mc1group      mc1g-6f4bd8989c-zprdw                   1/1       Running   0          2h        10.36.0.7    k003
(라) mc2group      deploy-test-1-8646c8d498-8nq59          1/1       Running   0          1h        10.44.0.17   k002
(마) mc2group      mc2g-6d4578df49-5m976                   1/1       Running   0          2h        10.36.0.8    k003
(바) mc2group      mc2g-6d4578df49-gz2df                   1/1       Running   0          2h        10.44.0.15   k002


아무 룰없을때 ping, web, multicast
[root@mc1g-6f4bd8989c-lh749 ~]# ping -c1 10.36.0.8
PING 10.36.0.8 (10.36.0.8) 56(84) bytes of data.
64 bytes from 10.36.0.8: icmp_seq=1 ttl=64 time=0.914 ms

--- 10.36.0.8 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 0.914/0.914/0.914/0.000 ms
[root@mc1g-6f4bd8989c-lh749 ~]# python send.py
[root@mc1g-6f4bd8989c-lh749 ~]# curl 10.44.0.17:8080
This is Web Server 1 running on 8080!
[root@mc1g-6f4bd8989c-lh749 ~]#

오케이... 이제 막는 테스트 시작


(5) 멀티캐스트 막기. ====> 결론... multicast는 namespace로 막히지 않는다. service로도 안막힐거다. 

참고사이트: https://github.com/ahmetb/kubernetes-network-policy-recipes/blob/master/04-deny-traffic-from-other-namespaces.md
이 사이트가 너무 그럴듯해서 잘된줄 믿었건만... 왠지 안막힘. 아무 트래픽도. 

그래서 다른 구글링하다가...
https://github.com/projectcalico/calico/issues/1049
이 페이지 중간에 

kind: NetworkPolicy
apiVersion: extensions/v1beta1
metadata:
  name: default-deny
  namespace: local
spec:
  podSelector:
  

요 룰이 적혀있어 아래와 같이 살짝 수정해서 적용해봄. 
root@k001:~/work# cat deny2.yaml
kind: NetworkPolicy
apiVersion: extensions/v1beta1
metadata:
  name: default-deny
  namespace: mc1group
spec:
  podSelector:

root@k001:~/work# kubectl apply -f deny2.yaml --validate=false
networkpolicy "default-deny" created

root@k001:~/work# kubectl get netpol --all-namespaces
NAMESPACE   NAME                         POD-SELECTOR   AGE
mc1group    default-deny                 <none>         4m
mc1group    deny-from-other-namespaces   <none>         31m  <-- 요건 잘 안됨.



이제 mc1group에서 쏘기 (이건 다 되어야함)
[root@mc1g-6f4bd8989c-lh749 ~]# curl 10.44.0.17:8080
This is Web Server 1 running on 8080![root@mc1g-6f4bd8989c-lh749 ~]# ping 10.36.0.8
PING 10.36.0.8 (10.36.0.8) 56(84) bytes of data.
64 bytes from 10.36.0.8: icmp_seq=1 ttl=64 time=0.825 ms
64 bytes from 10.36.0.8: icmp_seq=2 ttl=64 time=0.804 ms
^C
--- 10.36.0.8 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1001ms
rtt min/avg/max/mdev = 0.804/0.814/0.825/0.030 ms
[root@mc1g-6f4bd8989c-lh749 ~]# python send.py

양쪽 namespace 모두에서 열림. ㅠ.ㅠ;;
[root@mc1g-6f4bd8989c-zprdw ~]# python recv.py
ping from: mc1g-6f4bd8989c-lh749
[root@mc2g-6d4578df49-gz2df ~]# python recv.py
ping from: mc1g-6f4bd8989c-lh749    



이제 mc2group에서 mc1으로 쏘기 (이건 다 안되어야함)

[root@mc2g-6d4578df49-5m976 ~]# ping -c 1 10.44.0.14
PING 10.44.0.14 (10.44.0.14) 56(84) bytes of data.
^C
--- 10.44.0.14 ping statistics ---
1 packets transmitted, 0 received, 100% packet loss, time 0ms   --> ping 막힘

[root@mc2g-6d4578df49-5m976 ~]# curl 10.44.0.16:8080    --> http 막힘. 
^C
[root@mc2g-6d4578df49-5m976 ~]# python send.py
[root@mc2g-6d4578df49-5m976 ~]#

[root@mc1g-6f4bd8989c-zprdw ~]# python recv.py
ping from: mc1g-6f4bd8989c-lh749   <-- mc1group에서 쏘는것도 안막힘. 
ping from: mc2g-6d4578df49-5m976   <-- mc2group에서 쏘는건뭐.. 안막힘. 
